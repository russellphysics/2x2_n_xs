{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ba2882-42ce-431e-a149-4236e4d8065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "file_dir='/global/cfs/cdirs/dune/users/mkramer/mywork/2x2_sim/run-convert2h5/output/MiniRun3_1E19_RHC.convert2h5_v3/EDEPSIM_H5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56460c65-7bc3-45b5-9b81-b2fb1e866b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_spills(sim_h5):\n",
    "    return np.unique(sim_h5['trajectories']['eventID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49bbb931-bd95-4ebf-9815-b6b0241f58e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spill_data(sim_h5, spill_id):\n",
    "    ghdr_spill_mask = sim_h5['genie_hdr'][:]['eventID']==spill_id\n",
    "    gstack_spill_mask = sim_h5['genie_stack'][:]['eventID']==spill_id\n",
    "    traj_spill_mask = sim_h5['trajectories'][:]['eventID']==spill_id\n",
    "    vert_spill_mask = sim_h5['vertices'][:]['eventID']==spill_id\n",
    "    seg_spill_mask = sim_h5['segments'][:]['eventID']==spill_id\n",
    "    \n",
    "    ghdr = sim_h5['genie_hdr'][ghdr_spill_mask]\n",
    "    gstack = sim_h5['genie_stack'][gstack_spill_mask]\n",
    "    traj = sim_h5['trajectories'][traj_spill_mask]\n",
    "    vert = sim_h5['vertices'][vert_spill_mask]\n",
    "    seg = sim_h5['segments'][seg_spill_mask]\n",
    "    \n",
    "    return ghdr, gstack, traj, vert, seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a4e276-b319-4c85-a7e1-d9856fdce2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpc_bounds(i):\n",
    "    active_tpc_widths=[30.6, 130., 64.] # cm\n",
    "    tpcs_relative_to_module=[[-15.7,0.,0.],[15.7,0.,0.]]\n",
    "    modules_relative_to_2x2=[[-33.5,0.,-33.5],\n",
    "                            [33.5,0.,-33.5],\n",
    "                            [-33.5,0.,33.5],\n",
    "                            [33.5,0.,33.5]]\n",
    "    detector_center=[0.,52.25,0.]\n",
    "    tpc_bounds=np.array([-active_tpc_widths[i]/2., active_tpc_widths[i]/2.])\n",
    "    tpc_bounds_relative_to_2x2=[]\n",
    "    for tpc in tpcs_relative_to_module:\n",
    "        tpc_bound_relative_to_module = tpc_bounds + tpc[i]\n",
    "        for module in modules_relative_to_2x2:\n",
    "            bound = tpc_bound_relative_to_module + module[i]\n",
    "            tpc_bounds_relative_to_2x2.append(bound)\n",
    "    bounds_relative_to_NDhall = np.array(tpc_bounds_relative_to_2x2) + detector_center[i]\n",
    "    return np.unique(bounds_relative_to_NDhall, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cb8ad15-4562-4938-a328-6474c4937116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fiducialized_vertex(vert_pos):\n",
    "    flag=False; x_drift_flag=False; y_vertical_flag=False; z_beam_flag=False\n",
    "    for i in range(3):\n",
    "        for i_bounds, bounds in enumerate(tpc_bounds(i)):\n",
    "            if vert_pos[i]>bounds[0] and vert_pos[i]<bounds[1]:\n",
    "                if i==0: x_drift_flag=True; break\n",
    "                if i==1: y_vertical_flag=True\n",
    "                if i==2: z_beam_flag=True\n",
    "    if x_drift_flag==True and y_vertical_flag==True and z_beam_flag==True:\n",
    "        flag=True\n",
    "    return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2714de63-7642-4967-a6fb-9fd1cb0433c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_edep_charged_e(trackID, traj, seg):\n",
    "    seg_id_mask=seg['trackID']==trackID\n",
    "    total_e=0.\n",
    "    for sg in seg[seg_id_mask]: total_e+=sg['dE']\n",
    "    return total_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f770302-4664-4645-80c6-a30223d4332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_edep_length(trackID, traj, seg):\n",
    "    seg_id_mask=seg['trackID']==trackID\n",
    "    length=0.\n",
    "    for sg in seg[seg_id_mask]: \n",
    "        length+=np.sqrt((sg['x_start']-sg['x_end'])**2+\n",
    "                        (sg['y_start']-sg['y_end'])**2+\n",
    "                        (sg['z_start']-sg['z_end'])**2\n",
    "                       )\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d9f13a3-e47f-43f0-88f8-7772ea201075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_momentum(pxyz):\n",
    "    return float(np.sqrt(pxyz[0]**2+pxyz[1]**2+pxyz[2]**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "531f9751-dfbd-40e6-ac7f-de105a985f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_key_to_string(d):\n",
    "    out={}\n",
    "    for key in d.keys():\n",
    "        string_key=\"\"\n",
    "        max_length=len(key)\n",
    "        for i in range(max_length):\n",
    "            if i<len(key)-1: string_key+=str(key[i])+\"-\"\n",
    "            else: string_key+=str(key[i])\n",
    "        out[string_key]=d[key]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14388719-0019-4144-8766-099a816ae906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_to_json(d, name, if_tuple):\n",
    "    with open(name+\".json\",\"w\") as outfile:\n",
    "        if if_tuple==True:\n",
    "            updated_d = tuple_key_to_string(d)\n",
    "            json.dump(updated_d, outfile, indent=4)\n",
    "        else:\n",
    "            json.dump(d, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53aec898-5915-4bfa-bb1a-96a46e42b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_array_of_array_to_flat_list(a):\n",
    "    b = list(a)\n",
    "    return [list(c)[0] for c in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa9652c4-e0d2-47fd-94b6-1158b3cda177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(sim_h5):\n",
    "    unique_spill = get_unique_spills(sim_h5)\n",
    "    d=dict()\n",
    "    for spill_id in unique_spill:\n",
    "        ghdr, gstack, traj, vert, seg = get_spill_data(sim_h5, spill_id)\n",
    "        \n",
    "        traj_proton_mask = traj['pdgId']==2212\n",
    "        proton_traj = traj[traj_proton_mask]\n",
    "    \n",
    "        for pt in proton_traj:\n",
    "        \n",
    "            # REQUIRE proton contained in 2x2 active LAr\n",
    "            proton_start=pt['xyz_start']\n",
    "            if fiducialized_vertex(proton_start)==False: continue\n",
    "            if fiducialized_vertex(pt['xyz_end'])==False: continue\n",
    "        \n",
    "            # is nu vertex contained in 2x2 active LAr?\n",
    "            vert_mask = vert['vertexID']==pt['vertexID']\n",
    "            nu_vert = vert[vert_mask]\n",
    "            vert_loc = [nu_vert['x_vert'],nu_vert['y_vert'],nu_vert['z_vert']]\n",
    "            vert_loc = np_array_of_array_to_flat_list(vert_loc)\n",
    "            lar_fv = 1\n",
    "            if fiducialized_vertex(vert_loc)==False: lar_fv = 0\n",
    "        \n",
    "            # Find proton parent PDG \n",
    "            parent_mask = traj['trackID']==pt['parentID']\n",
    "            parent_pdg=traj[parent_mask]['pdgId']\n",
    "            if pt['parentID']==-1:\n",
    "                ghdr_mask=ghdr['vertexID']==pt['vertexID']\n",
    "                parent_pdg=ghdr[ghdr_mask]['nu_pdg']\n",
    "        \n",
    "            # Find proton grandparent PDG \n",
    "            grandparent_mask = traj['trackID']==traj[parent_mask]['parentID']\n",
    "            grandparent_trackid = traj[grandparent_mask]['trackID']\n",
    "            grandparent_pdg = traj[grandparent_mask]['pdgId']\n",
    "            if grandparent_trackid.size>0:\n",
    "                if grandparent_trackid==-1:\n",
    "                    ghdr_mask=ghdr['vertexID']==pt['vertexID']\n",
    "                    grandparent_pdg=ghdr[ghdr_mask]['nu_pdg']\n",
    "            grandparent_pdg=list(grandparent_pdg)\n",
    "            if len(grandparent_pdg)==0: grandparent_pdg=[0]\n",
    "            \n",
    "            if parent_pdg[0] not in [12,14,16,-12,-14,-16]:\n",
    "                parent_total_energy = float(list(traj[parent_mask]['E_start'])[0])\n",
    "                parent_length = float(total_edep_length(traj[parent_mask]['trackID'], traj, seg))\n",
    "                parent_start_momentum = float(three_momentum(traj[parent_mask]['pxyz_start'][0]))\n",
    "                parent_end_momentum = float(three_momentum(traj[parent_mask]['pxyz_end'][0]))\n",
    "            else:\n",
    "                parent_total_energy = float(-1) \n",
    "                parent_length = float(-1)\n",
    "                parent_start_momentum = float(-1)\n",
    "                parent_end_momentum = float(-1)\n",
    "                \n",
    "            gstack_mask = gstack['vertexID']==pt['vertexID']\n",
    "            gstack_trackID = gstack[gstack_mask]['trackID']\n",
    "            primary_length=[]; primary_pdg=[]\n",
    "            for gid in gstack_trackID:\n",
    "                primary_mask = traj['trackID']==gid\n",
    "                primary_start = traj[primary_mask]['xyz_start']\n",
    "                primary_end = traj[primary_mask]['xyz_end']\n",
    "                p_pdg = traj[primary_mask]['pdgId']\n",
    "                if len(p_pdg)==1:\n",
    "                    primary_pdg.append(int(p_pdg[0]))\n",
    "                    dis = np.sqrt( (primary_start[0][0]-primary_end[0][0])**2+\n",
    "                                   (primary_start[0][1]-primary_end[0][1])**2+\n",
    "                                   (primary_start[0][2]-primary_end[0][2])**2)\n",
    "                    primary_length.append(float(dis))\n",
    "                      \n",
    "            p_start = proton_start.tolist()\n",
    "            p_vtx = []\n",
    "            for i in p_start: p_vtx.append(float(i))\n",
    "            \n",
    "            nu_vtx=[]\n",
    "            for i in vert_loc: nu_vtx.append(float(i))\n",
    "            \n",
    "            d[(spill_id, pt['vertexID'], pt['trackID'])]=dict(\n",
    "                lar_fv=int(lar_fv),\n",
    "                \n",
    "                p_vtx=p_vtx,\n",
    "                nu_vtx=nu_vtx,\n",
    "                \n",
    "                proton_total_energy = float(pt['E_start']),\n",
    "                proton_vis_energy = float(total_edep_charged_e(pt['trackID'], traj, seg)),\n",
    "                proton_length = float(total_edep_length(pt['trackID'], traj, seg)),\n",
    "                proton_start_momentum = float(three_momentum(pt['pxyz_start'])),\n",
    "                proton_end_momentum = float(three_momentum(pt['pxyz_end'])),\n",
    "                \n",
    "                parent_total_energy = parent_total_energy, \n",
    "                parent_length = parent_length, \n",
    "                parent_start_momentum = parent_start_momentum, \n",
    "                parent_end_momentum = parent_end_momentum, \n",
    "                \n",
    "                nu_proton_dt = float(pt['t_start']) - float(nu_vert['t_vert'][0]),\n",
    "                nu_proton_distance = float(np.sqrt( (proton_start[0]-vert_loc[0])**2+\n",
    "                                          (proton_start[1]-vert_loc[1])**2+\n",
    "                                          (proton_start[2]-vert_loc[2])**2 )),\n",
    "                \n",
    "                parent_pdg=int(parent_pdg[0]),\n",
    "                grandparent_pdg=int(grandparent_pdg[0]),\n",
    "                primary_pdg=primary_pdg,                \n",
    "                primary_length=primary_length\n",
    "            )\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "026e4e9e-a0d1-4c1b-a4f3-3b8873e93464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1988140/189764794.py:33: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  grandparent_mask = traj['trackID']==traj[parent_mask]['parentID']\n"
     ]
    }
   ],
   "source": [
    "for filename in glob.glob(file_dir+'*.EDEPSIM.h5'):\n",
    "    file_no = filename.split(\".\")[-3]\n",
    "    sim_h5=h5py.File(filename,'r')\n",
    "    d = process_file(sim_h5)\n",
    "    save_dict_to_json(d, \"n_tof_\"+file_no, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
